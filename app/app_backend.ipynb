{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de9f7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 250000 samples\n",
      "Distribution:\n",
      " category\n",
      "ENTERTAINMENT     25000\n",
      "POLITICS          25000\n",
      "BUSINESS          25000\n",
      "TECH              25000\n",
      "TRAVEL            25000\n",
      "SCIENCE           25000\n",
      "FOOD & DRINK      25000\n",
      "SPORTS            25000\n",
      "WORLD NEWS        25000\n",
      "HEALTHY LIVING    25000\n",
      "Name: count, dtype: int64\n",
      "Cleaning text...\n",
      "TF-IDF matrix shape: (250000, 30000)\n",
      "Training samples: 200000\n",
      "Test samples: 50000\n",
      "Training model...\n",
      "\n",
      "==================================================\n",
      "MODEL ACCURACY: 85.69%\n",
      "==================================================\n",
      "\n",
      "Model saved to: C:\\Users\\ishfa\\OneDrive\\Documents\\MU 6TH SEM\\AI\\AI Final Project\\News_Domain_Classification\\app\\domain_classifier_model.pkl\n",
      "Vectorizer saved to: C:\\Users\\ishfa\\OneDrive\\Documents\\MU 6TH SEM\\AI\\AI Final Project\\News_Domain_Classification\\app\\tfidf_vectorizer.pkl\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import joblib\n",
    "\n",
    "#NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "#Loading dataset\n",
    "df = pd.read_csv('../dataset/domain_classification_dataset.csv')\n",
    "\n",
    "print(f\"Loaded {len(df)} samples\")\n",
    "print(\"Distribution:\\n\", df['category'].value_counts())\n",
    "\n",
    "#Cleaning text function\n",
    "def clean_text(text):\n",
    "    if isinstance(text, float) or text is None:\n",
    "        text = \"\"\n",
    "    text = str(text).lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "#Applying cleaning\n",
    "print(\"Cleaning text...\")\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "\n",
    "#TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    max_features=30000,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "y = df['category']\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {X.shape}\")\n",
    "\n",
    "#Spliting data into train[80%] and test[20%]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y \n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "#Train Logistic Regression\n",
    "print(\"Training model...\")\n",
    "base_svc = LinearSVC(C=0.5, class_weight='balanced', max_iter=2000)\n",
    "model = CalibratedClassifierCV(base_svc, cv=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Prediction on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Accuracy Calculation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"MODEL ACCURACY: {accuracy * 100:.2f}%\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "#Saving model and vectorizer\n",
    "save_path_model = r'C:\\Users\\ishfa\\OneDrive\\Documents\\MU 6TH SEM\\AI\\AI Final Project\\News_Domain_Classification\\app\\domain_classifier_model.pkl'\n",
    "save_path_vectorizer = r'C:\\Users\\ishfa\\OneDrive\\Documents\\MU 6TH SEM\\AI\\AI Final Project\\News_Domain_Classification\\app\\tfidf_vectorizer.pkl'\n",
    "\n",
    "joblib.dump(model, save_path_model)\n",
    "joblib.dump(vectorizer, save_path_vectorizer)\n",
    "\n",
    "\n",
    "print(f\"\\nModel saved to: {save_path_model}\")\n",
    "print(f\"Vectorizer saved to: {save_path_vectorizer}\")\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
